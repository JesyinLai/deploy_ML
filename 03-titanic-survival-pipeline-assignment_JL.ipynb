{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_to_object_array' from 'sklearn.utils.validation' (C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\utils\\validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 42\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     AddMissingIndicator,\n\u001b[0;32m     37\u001b[0m     MeanMedianImputer,\n\u001b[0;32m     38\u001b[0m     CategoricalImputer,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# for encoding categorical variables\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     RareLabelEncoder,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m#OrdinalEncoder,\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     OneHotEncoder\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\feature_engine\\encoding\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe module encoding includes classes to transform categorical variables into numerical.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcount_frequency\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountFrequencyEncoder\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeEncoder\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmean_encoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MeanEncoder\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mone_hot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\feature_engine\\encoding\\decision_tree.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubstitute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe_checks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_contains_na, check_X_y\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscretisation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeDiscretiser\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_helper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_parameter_unseen\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     CategoricalInitMixin,\n\u001b[0;32m     33\u001b[0m     CategoricalMethodsMixin,\n\u001b[0;32m     34\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\feature_engine\\discretisation\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe module discretisation includes classes to sort continuous variables into bins or\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mintervals.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marbitrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArbitraryDiscretiser\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeDiscretiser\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mequal_frequency\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EqualFrequencyDiscretiser\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mequal_width\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EqualWidthDiscretiser\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\feature_engine\\discretisation\\decision_tree.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier, DecisionTreeRegressor\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets, type_of_target\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_numerical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseNumericalTransformer\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\tree\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Decision tree based models for classification and regression.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     BaseDecisionTree,\n\u001b[0;32m      5\u001b[0m     DecisionTreeClassifier,\n\u001b[0;32m      6\u001b[0m     DecisionTreeRegressor,\n\u001b[0;32m      7\u001b[0m     ExtraTreeClassifier,\n\u001b[0;32m      8\u001b[0m     ExtraTreeRegressor,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz, export_text, plot_tree\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseDecisionTree\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecisionTreeClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m ]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\tree\\_classes.py:44\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     _assert_all_finite_element_wise,\n\u001b[0;32m     40\u001b[0m     _check_sample_weight,\n\u001b[0;32m     41\u001b[0m     assert_all_finite,\n\u001b[0;32m     42\u001b[0m     check_is_fitted,\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _criterion, _splitter, _tree\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Criterion\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n",
      "File \u001b[1;32m_criterion.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._criterion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_splitter.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._splitter\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._tree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\neighbors\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The k-nearest neighbors algorithms.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ball_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BallTree\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE, sort_graph_by_row_values\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier, RadiusNeighborsClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     KNeighborsTransformer,\n\u001b[0;32m      8\u001b[0m     RadiusNeighborsTransformer,\n\u001b[0;32m      9\u001b[0m     kneighbors_graph,\n\u001b[0;32m     10\u001b[0m     radius_neighbors_graph,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\neighbors\\_base.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_object_array, check_is_fitted, check_non_negative\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ball_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BallTree\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kd_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDTree\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_to_object_array' from 'sklearn.utils.validation' (C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\sklearn\\utils\\validation.py)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# ========== NEW IMPORTS ========\n",
    "# Respect to notebook 02-Predicting-Survival-Titanic-Solution\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for imputation\n",
    "from feature_engine.imputation import (\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    #OrdinalEncoder,\n",
    "    OneHotEncoder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\formatters.py\", line 344, in __call__\n",
      "    return method()\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\pandas\\core\\frame.py\", line 798, in _repr_html_\n",
      "    typ=manager,\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 988, in to_html\n",
      "AttributeError: 'NotebookFormatter' object has no attribute 'get_result'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat body  \\\n",
       "0      29      0      0   24160  211.3375       B5        S    2    ?   \n",
       "1  0.9167      1      2  113781    151.55  C22 C26        S   11    ?   \n",
       "2       2      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "3      30      1      2  113781    151.55  C22 C26        S    ?  135   \n",
       "4      25      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\formatters.py\", line 344, in __call__\n",
      "    return method()\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\pandas\\core\\frame.py\", line 798, in _repr_html_\n",
      "    typ=manager,\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 988, in to_html\n",
      "AttributeError: 'NotebookFormatter' object has no attribute 'get_result'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\jlai\\Anaconda3\\envs\\IBM\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare cabin embarked  \\\n",
       "0       1         1  female  29.0000      0      0  211.3375    B5        S   \n",
       "1       1         1    male   0.9167      1      2  151.5500   C22        S   \n",
       "2       1         0  female   2.0000      1      2  151.5500   C22        S   \n",
       "3       1         0    male  30.0000      1      2  151.5500   C22        S   \n",
       "4       1         0  female  25.0000      1      2  151.5500   C22        S   \n",
       "\n",
       "    title  \n",
       "0    Miss  \n",
       "1  Master  \n",
       "2    Miss  \n",
       "3      Mr  \n",
       "4     Mrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data set\n",
    "\n",
    "# data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Assignment\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables to be used in the pipeline's transformers\n",
    "\n",
    "NUMERICAL_VARIABLES = [ 'age', 'fare']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['sex', 'cabin', 'embarked', 'title']\n",
    "\n",
    "CABIN = ['cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1047, 9), (262, 9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Extract fist letter of variable\n",
    "\n",
    "    def __init__(self,variables):\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "            \n",
    "        self.variables=variables\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        for feature in self.variables:\n",
    "            X[feature]=X['feature'].str[0]\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Impute categorical variables with string missing\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with the median\n",
    "- Extract first letter from cabin\n",
    "- Group rare Categories\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RareLabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# set up the pipeline\u001b[39;00m\n\u001b[0;32m      2\u001b[0m titanic_pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# ===== IMPUTATION =====\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# impute categorical variables with string 'missing'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_imputation\u001b[39m\u001b[38;5;124m'\u001b[39m, CategoricalImputer(\n\u001b[0;32m      7\u001b[0m         imputation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m,variables\u001b[38;5;241m=\u001b[39mCATEGORICAL_VARIABLES)),\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# add missing indicator to numerical variables\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_indicator\u001b[39m\u001b[38;5;124m'\u001b[39m, AddMissingIndicator(variables\u001b[38;5;241m=\u001b[39m(NUMERICAL_VARIABLES))),\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# impute numerical variables with the median\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_imputation\u001b[39m\u001b[38;5;124m'\u001b[39m,MeanMedianImputer(imputation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, variables\u001b[38;5;241m=\u001b[39m(NUMERICAL_VARIABLES))),\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Extract first letter from cabin\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract_letter\u001b[39m\u001b[38;5;124m'\u001b[39m, ExtractLetterTransformer(variables\u001b[38;5;241m=\u001b[39mCABIN)),\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# == CATEGORICAL ENCODING ======\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# remove categories present in less than 5% of the observations (0.05)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# group them in one category called 'Rare'\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrare_label_encoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mRareLabelEncoder\u001b[49m(\n\u001b[0;32m     24\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, n_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, variables\u001b[38;5;241m=\u001b[39mCATEGORICAL_VARIABLES)),\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# encode categorical variables using one hot encoding into k-1 variables\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_encoder\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(\n\u001b[0;32m     29\u001b[0m         drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39mCATEGORICAL_VARIABLES)),\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# scale using standardization\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# logistic regression (use C=0.0005 and random_state=0)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogit\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m     36\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RareLabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string 'missing'\n",
    "    ('categorical_imputation', CategoricalImputer(\n",
    "        imputation_method='missing',variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator', AddMissingIndicator(variables=(NUMERICAL_VARIABLES))),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    ('median_imputation',MeanMedianImputer(imputation_method='median', variables=(NUMERICAL_VARIABLES))),\n",
    "\n",
    "\n",
    "    # Extract first letter from cabin\n",
    "    ('extract_letter', ExtractLetterTransformer(variables=CABIN)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    ('rare_label_encoder', RareLabelEncoder(\n",
    "        tol=0.05, n_categories=1, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    ('categorical_encoder', OneHotEncoder(\n",
    "        drop_last=True, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # scale using standardization\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    # logistic regression (use C=0.0005 and random_state=0)\n",
    "    ('Logit', LogisticRegression(C=0.0005, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('categorical_imputation',\n",
       "                 CategoricalImputer(variables=['sex', 'cabin', 'embarked',\n",
       "                                               'title'])),\n",
       "                ('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['age', 'fare'])),\n",
       "                ('median_imputation',\n",
       "                 MeanMedianImputer(variables=['age', 'fare'])),\n",
       "                ('extract_letter',\n",
       "                 ExtractLetterTransformer(variables=['cabin'])),\n",
       "                ('rare_label_encoder',\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=['sex', 'cabin', 'embarked',\n",
       "                                             'title'])),\n",
       "                ('categorical_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['sex', 'cabin', 'embarked',\n",
       "                                          'title'])),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the pipeline\n",
    "titanic_pipe.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc-auc: 0.8450386398763523\n",
      "train accuracy: 0.7220630372492837\n",
      "\n",
      "test roc-auc: 0.8354629629629629\n",
      "test accuracy: 0.7137404580152672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "class_ = titanic_pipe.predict(X_train)\n",
    "pred = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = titanic_pipe.predict(X_test)\n",
    "pred = titanic_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
